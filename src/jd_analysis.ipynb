{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/boluo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /Users/boluo/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('tagsets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'source', 'job-title', 'ID', 'company', 'Vacancies',\n",
       "       'Estimated Start Date', 'Estimated End Date', 'Job Description',\n",
       "       'Learning Outcomes', 'Finance', 'Healthcare', 'Supply, Logistics',\n",
       "       'Retail, Marketing', 'Research', 'Public Sector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df = pd.read_csv('TalentConnectWithIndustries.csv')\n",
    "job_df = job_df.rename(columns={\"Job Title\": \"job-title\",\"Unnamed: 0\": \"index\",\"#\": \"source\",\"Employer\":\"company\",\"Internship/Project Description\":\"Job Description\"})\n",
    "job_df.loc[:,'source'] = 'TalentConnect'\n",
    "job_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "other_stop_words = ['skill','join','center','increase','imporve','turning','work','tool','postion','within','big','main','description','part','people','make','nation','come','Singapore','insight','strong','customer','role','develop','requirement','quality','working','support','solution','provide','knowledge','reporting','problem','platform','job','key','performance','external','bi','build','year','opportunity','excellent','good','issue','technical','improvement','internal','eg','etl','information','required','preferred','including','help','also','perform','understand','set','understanding','identify','solving','using','report','new','ability','source','growth','various','industry','etc','well','looking','da','d2c','field','use','trend','sources','able','us']\n",
    "stop = stop + other_stop_words\n",
    "def clean_text(text,stop):\n",
    "\ttext = text.lower()\n",
    "\ttext = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "\ttext = re.sub(r'[0-9]+', '',text)\n",
    "\ttext = ' '.join(text.split())\n",
    "\n",
    "\tcleaned = word_tokenize(text)\n",
    "\ttokens = [x for x in cleaned if x not in stop]\n",
    "\treturn tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemming(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem = [lemmatizer.lemmatize(x) for x in tokens]\n",
    "    return lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(tokens):\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    stems = [stemmer.stem(x) for x in tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data engineer', 'business analyst', 'data analyst', 'data scientist', 'machine learning engineer']\n"
     ]
    }
   ],
   "source": [
    "job_titles = ['data engineer','business analyst','data analyst','data scientist','machine learning engineer']\n",
    "job_titles_split = [x.split(' ')  for x in job_titles]\n",
    "job_titles_split[3].append('science')\n",
    "print(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_category(title,keywords):\n",
    "    category = -1\n",
    "    score = 0\n",
    "    for i in range(len(job_titles_split)):\n",
    "        score_1 = 0\n",
    "        for word in title:\n",
    "            if (word in job_titles_split[i]):\n",
    "                score_1 = score_1+1\n",
    "        score_1 = score_1/len(job_titles_split[i])\n",
    "        score_2 = 0\n",
    "        for word in job_titles_split[i]:\n",
    "            if(word in keywords.keys()):\n",
    "                score_2+=keywords[word]\n",
    "        if(score_1+score_2>score):\n",
    "            score = score_1 +score_2\n",
    "            category =i\n",
    "        score_1=0\n",
    "        score_2=0\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_title(text,keywords):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    text = re.sub(r'[0-9]+', '',text)\n",
    "    text = \" \".join(text.split())\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = nltk.pos_tag(lemming(tokens))\n",
    "    new_title = []\n",
    "    for lem in tagged:\n",
    "        if(lem[1] in ['NN','NNS','JJ']):\n",
    "            new_title.append(lem[0])\n",
    "    category = find_category(new_title,keywords)\n",
    "    return job_titles[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = []\n",
    "tokens = []\n",
    "lems = []\n",
    "stems = []\n",
    "tagged = []\n",
    "all_tags = []\n",
    "\n",
    "description = 'Job Description'\n",
    "title = 'job-title'\n",
    "\n",
    "for index, row in job_df.iterrows():\n",
    "    cur = clean_text(job_df[description][index],stop)\n",
    "    lem_cur = lemming(cur)\n",
    "    stem_cur = stemming(cur)\n",
    "    with_tag = nltk.pos_tag(lem_cur)\n",
    "\n",
    "    tokens.append(cur)\n",
    "    lems.append(lem_cur)\n",
    "    stems.append(stem_cur)\n",
    "    tagged.append(with_tag)\n",
    "    all_tags.extend(with_tag)\n",
    "    temp = []\n",
    "\n",
    "    grammar = ['NN','NNS','VB','VBG','VBD','VBN','VBP','VBZ']\n",
    "    for x in with_tag:\n",
    "        if(x[1] in grammar):\n",
    "            temp.append(x[0])\n",
    "    temp = ' '.join(temp)\n",
    "    cleaned_text.append(temp)\n",
    "\n",
    "job_df['tokens'] = tokens\n",
    "job_df['lems'] = lems\n",
    "job_df['tagged'] = tagged\n",
    "job_df['stems'] = stems\n",
    "job_df['cleaned_text'] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = job_df['cleaned_text']\n",
    "def vectorize(vocabulary,max_df,stop,low,high):\n",
    "    cv = CountVectorizer(max_df=max_df,stop_words=stop,analyzer='word',ngram_range=(low,high))\n",
    "    count_vector = cv.fit_transform(vocabulary)\n",
    "    feature_names = cv.get_feature_names()\n",
    "    tfidf_transformer = TfidfTransformer(smooth_idf = True,use_idf = True)\n",
    "    tfidf_vector = tfidf_transformer.fit(count_vector)\n",
    "\n",
    "    sum_words = count_vector.sum(axis = 0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return cv, tfidf_transformer, feature_names, tfidf_vector, words_freq\n",
    "\n",
    "cv, tfidf_transformer, feature_names, tfidf_vector, words_freq = vectorize(vocabulary,0.6,stop,1,2)\n",
    "\n",
    "#cos_sim = cosine_similarity(tfidf_vector, tfidf_vector)\n",
    "#words_freq[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col,coo_matrix.data)\n",
    "    return sorted(tuples,key = lambda x:(x[1],x[0]),reverse = True)\n",
    "\n",
    "def extract_topn(feature_names,sorted_words,topn):\n",
    "    n = topn\n",
    "    if (n<1): n = math.floor(len(sorted_words)*topn)\n",
    "    sorted_words = sorted_words[:n]\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    for index, score in sorted_words:\n",
    "        score_vals.append(round(score,3))\n",
    "        feature_vals.append(feature_names[index])\n",
    "    results = {}\n",
    "    for index in range(len(feature_vals)):\n",
    "        results[feature_vals[index]] = score_vals[index]\n",
    "    return results\n",
    "\n",
    "\n",
    "key_words = []\n",
    "title_norm = []\n",
    "for index, row in job_df.iterrows():\n",
    "    doc = job_df['cleaned_text'][index]\n",
    "    tfidf_vector = tfidf_transformer.transform(cv.transform([doc]))\n",
    "    sorted_words = sort_coo(tfidf_vector.tocoo())\n",
    "    keywords = extract_topn(feature_names,sorted_words,0.25)\n",
    "    key_words.append(keywords)\n",
    "    title_norm.append(normalize_title(job_df[title][index],keywords))\n",
    "job_df['normalized_title'] = title_norm\n",
    "job_df['key_words'] = key_words\n",
    "job_df.to_csv('TalentConnect.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>job-title</th>\n",
       "      <th>ID</th>\n",
       "      <th>company</th>\n",
       "      <th>Vacancies</th>\n",
       "      <th>Estimated Start Date</th>\n",
       "      <th>Estimated End Date</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Learning Outcomes</th>\n",
       "      <th>...</th>\n",
       "      <th>Retail, Marketing</th>\n",
       "      <th>Research</th>\n",
       "      <th>Public Sector</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lems</th>\n",
       "      <th>tagged</th>\n",
       "      <th>stems</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>normalized_title</th>\n",
       "      <th>key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>College Intern - Data Science (Remote)</td>\n",
       "      <td>67596</td>\n",
       "      <td>HP SINGAPORE PTE. LTD</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>Team Description: This position is with the D...</td>\n",
       "      <td>Team Description: This position is with the D...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[team, position, data, analytics, team, smart,...</td>\n",
       "      <td>[team, position, data, analytics, team, smart,...</td>\n",
       "      <td>[(team, NN), (position, NN), (data, NNS), (ana...</td>\n",
       "      <td>[team, posit, data, analyt, team, smart, manuf...</td>\n",
       "      <td>team position data analytics team manufacturin...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>{'smarc': 0.208, 'manufacturing': 0.186, 'anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>66426</td>\n",
       "      <td>Rio Tinto</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>This role is a great opportunity to be involve...</td>\n",
       "      <td>This role is a great opportunity to be involve...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[great, involved, delivery, analytics, proof, ...</td>\n",
       "      <td>[great, involved, delivery, analytics, proof, ...</td>\n",
       "      <td>[(great, JJ), (involved, JJ), (delivery, NN), ...</td>\n",
       "      <td>[great, involv, deliveri, analyt, proof, conce...</td>\n",
       "      <td>delivery analytics proof concept play executio...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>{'science': 0.162, 'data science': 0.16, 'code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>Data Science_AMTNP</td>\n",
       "      <td>68454</td>\n",
       "      <td>GlaxoSmithKline / Glaxo Wellcome Manufacturing...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Modern manufacturing is no longer just about f...</td>\n",
       "      <td>Modern manufacturing is no longer just about f...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[modern, manufacturing, longer, finding, ways,...</td>\n",
       "      <td>[modern, manufacturing, longer, finding, way, ...</td>\n",
       "      <td>[(modern, JJ), (manufacturing, NN), (longer, R...</td>\n",
       "      <td>[modern, manufactur, longer, find, way, oper, ...</td>\n",
       "      <td>manufacturing finding way operate reducing exp...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>{'site': 0.26, 'manufacturing': 0.2, 'way': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>Digital Performance Management_NPAMT</td>\n",
       "      <td>68455</td>\n",
       "      <td>GlaxoSmithKline / Glaxo Wellcome Manufacturing...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>In alignment with the digitalisation, data and...</td>\n",
       "      <td>In alignment with the digitalisation, data and...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[alignment, digitalisation, data, analytics, s...</td>\n",
       "      <td>[alignment, digitalisation, data, analytics, s...</td>\n",
       "      <td>[(alignment, JJ), (digitalisation, NN), (data,...</td>\n",
       "      <td>[align, digitalis, data, analyt, strategi, exi...</td>\n",
       "      <td>digitalisation data analytics strategy exists ...</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>{'phase': 0.297, 'dashboard': 0.21, 'student':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>Digital Twin_NPAMT</td>\n",
       "      <td>68465</td>\n",
       "      <td>GlaxoSmithKline / Glaxo Wellcome Manufacturing...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Opportunity Statement  Dolutegravir (or “DTG”)...</td>\n",
       "      <td>Opportunity Statement  Dolutegravir (or “DTG”)...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[statement, dolutegravir, “, dtg, ”, first, ap...</td>\n",
       "      <td>[statement, dolutegravir, “, dtg, ”, first, ap...</td>\n",
       "      <td>[(statement, NN), (dolutegravir, NN), (“, NNP)...</td>\n",
       "      <td>[statement, dolutegravir, “, dtg, ”, first, ap...</td>\n",
       "      <td>statement dolutegravir dtg approved state food...</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>{'twin': 0.368, 'plant': 0.24, 'campaign': 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>Intern - Data Science (ref: 342612)</td>\n",
       "      <td>172146</td>\n",
       "      <td>Glaxo Wellcome Manufacturing Pte Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>2023-05-26</td>\n",
       "      <td>Office Location: Jurong  Hiring Manager: AMT S...</td>\n",
       "      <td>Office Location: Jurong  Hiring Manager: AMT S...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[office, location, jurong, hiring, manager, am...</td>\n",
       "      <td>[office, location, jurong, hiring, manager, am...</td>\n",
       "      <td>[(office, NN), (location, NN), (jurong, IN), (...</td>\n",
       "      <td>[offic, locat, jurong, hire, manag, amt, singa...</td>\n",
       "      <td>office location hiring manager amt singapore p...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>{'gsk': 0.213, 'disease': 0.199, 'place': 0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>Digital Platform &amp; Integration (Data Science I...</td>\n",
       "      <td>176054</td>\n",
       "      <td>ENGIE SERVICES SINGAPORE PTE. LTD.</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>2023-05-31</td>\n",
       "      <td>Job Description:  ·Provide detailed documentat...</td>\n",
       "      <td>Job Description:  ·Provide detailed documentat...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[·provide, detailed, documentation, capture, p...</td>\n",
       "      <td>[·provide, detailed, documentation, capture, p...</td>\n",
       "      <td>[(·provide, RB), (detailed, JJ), (documentatio...</td>\n",
       "      <td>[·provid, detail, document, captur, project, r...</td>\n",
       "      <td>documentation capture project requirement stan...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>{'format': 0.15, 'data format': 0.15, 'configu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>System Analyst Associate</td>\n",
       "      <td>176797</td>\n",
       "      <td>Maha Chemicals (Asia) Pte Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Responsibilities: - Draw flow charts to visual...</td>\n",
       "      <td>Responsibilities: - Draw flow charts to visual...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[responsibilities, draw, flow, charts, visuali...</td>\n",
       "      <td>[responsibility, draw, flow, chart, visualize,...</td>\n",
       "      <td>[(responsibility, NN), (draw, NN), (flow, JJ),...</td>\n",
       "      <td>[respons, draw, flow, chart, visual, workflow,...</td>\n",
       "      <td>responsibility draw chart visualize process ga...</td>\n",
       "      <td>business analyst</td>\n",
       "      <td>{'visualize process': 0.158, 'user test': 0.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>Intern – Sales Operations, APJ</td>\n",
       "      <td>176941</td>\n",
       "      <td>Thermo Fisher Scientific Ltd</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>How Will You Make an Impact?  The Sales Operat...</td>\n",
       "      <td>How Will You Make an Impact?  The Sales Operat...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[impact, sales, operations, intern, apj, suppo...</td>\n",
       "      <td>[impact, sale, operation, intern, apj, support...</td>\n",
       "      <td>[(impact, JJ), (sale, NN), (operation, NN), (i...</td>\n",
       "      <td>[impact, sale, oper, intern, apj, support, ove...</td>\n",
       "      <td>sale operation apj supporting life science pro...</td>\n",
       "      <td>business analyst</td>\n",
       "      <td>{'sale': 0.465, 'sale operation': 0.302, 'anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151</td>\n",
       "      <td>TalentConnect</td>\n",
       "      <td>Management Intern (HR Digital Workplace)</td>\n",
       "      <td>176981</td>\n",
       "      <td>Tan Tock Seng Hospital</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>We are looking for an aspiring digital transfo...</td>\n",
       "      <td>We are looking for an aspiring digital transfo...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[aspiring, digital, transformer, onboard, hr, ...</td>\n",
       "      <td>[aspiring, digital, transformer, onboard, hr, ...</td>\n",
       "      <td>[(aspiring, VBG), (digital, JJ), (transformer,...</td>\n",
       "      <td>[aspir, digit, transform, onboard, hr, digit, ...</td>\n",
       "      <td>aspiring transformer onboard hr workplace team...</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>{'successfactor': 0.243, 'digitalization': 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index         source                                          job-title  \\\n",
       "0        1  TalentConnect             College Intern - Data Science (Remote)   \n",
       "1        2  TalentConnect                              Junior Data Scientist   \n",
       "2        3  TalentConnect                                 Data Science_AMTNP   \n",
       "3        4  TalentConnect               Digital Performance Management_NPAMT   \n",
       "4        5  TalentConnect                                 Digital Twin_NPAMT   \n",
       "..     ...            ...                                                ...   \n",
       "146    147  TalentConnect                Intern - Data Science (ref: 342612)   \n",
       "147    148  TalentConnect  Digital Platform & Integration (Data Science I...   \n",
       "148    149  TalentConnect                           System Analyst Associate   \n",
       "149    150  TalentConnect                     Intern – Sales Operations, APJ   \n",
       "150    151  TalentConnect           Management Intern (HR Digital Workplace)   \n",
       "\n",
       "         ID                                            company  Vacancies  \\\n",
       "0     67596                              HP SINGAPORE PTE. LTD          3   \n",
       "1     66426                                          Rio Tinto          2   \n",
       "2     68454  GlaxoSmithKline / Glaxo Wellcome Manufacturing...          1   \n",
       "3     68455  GlaxoSmithKline / Glaxo Wellcome Manufacturing...          1   \n",
       "4     68465  GlaxoSmithKline / Glaxo Wellcome Manufacturing...          1   \n",
       "..      ...                                                ...        ...   \n",
       "146  172146               Glaxo Wellcome Manufacturing Pte Ltd          1   \n",
       "147  176054                 ENGIE SERVICES SINGAPORE PTE. LTD.          1   \n",
       "148  176797                      Maha Chemicals (Asia) Pte Ltd          1   \n",
       "149  176941                       Thermo Fisher Scientific Ltd          1   \n",
       "150  176981                             Tan Tock Seng Hospital          1   \n",
       "\n",
       "    Estimated Start Date Estimated End Date  \\\n",
       "0             2021-06-01         2021-12-27   \n",
       "1             2021-05-03         2021-12-31   \n",
       "2             2021-07-05         2021-12-31   \n",
       "3             2021-07-05         2021-12-31   \n",
       "4             2021-07-05         2021-12-31   \n",
       "..                   ...                ...   \n",
       "146           2023-01-09         2023-05-26   \n",
       "147           2022-12-19         2023-05-31   \n",
       "148           2022-12-01         2023-05-01   \n",
       "149           2023-01-03         2023-06-05   \n",
       "150           2023-01-09         2023-06-02   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0     Team Description: This position is with the D...   \n",
       "1    This role is a great opportunity to be involve...   \n",
       "2    Modern manufacturing is no longer just about f...   \n",
       "3    In alignment with the digitalisation, data and...   \n",
       "4    Opportunity Statement  Dolutegravir (or “DTG”)...   \n",
       "..                                                 ...   \n",
       "146  Office Location: Jurong  Hiring Manager: AMT S...   \n",
       "147  Job Description:  ·Provide detailed documentat...   \n",
       "148  Responsibilities: - Draw flow charts to visual...   \n",
       "149  How Will You Make an Impact?  The Sales Operat...   \n",
       "150  We are looking for an aspiring digital transfo...   \n",
       "\n",
       "                                     Learning Outcomes  ...  \\\n",
       "0     Team Description: This position is with the D...  ...   \n",
       "1    This role is a great opportunity to be involve...  ...   \n",
       "2    Modern manufacturing is no longer just about f...  ...   \n",
       "3    In alignment with the digitalisation, data and...  ...   \n",
       "4    Opportunity Statement  Dolutegravir (or “DTG”)...  ...   \n",
       "..                                                 ...  ...   \n",
       "146  Office Location: Jurong  Hiring Manager: AMT S...  ...   \n",
       "147  Job Description:  ·Provide detailed documentat...  ...   \n",
       "148  Responsibilities: - Draw flow charts to visual...  ...   \n",
       "149  How Will You Make an Impact?  The Sales Operat...  ...   \n",
       "150  We are looking for an aspiring digital transfo...  ...   \n",
       "\n",
       "     Retail, Marketing  Research  Public Sector  \\\n",
       "0                False     False          False   \n",
       "1                 True     False          False   \n",
       "2                False     False          False   \n",
       "3                False     False          False   \n",
       "4                False     False          False   \n",
       "..                 ...       ...            ...   \n",
       "146              False     False          False   \n",
       "147              False     False          False   \n",
       "148              False     False          False   \n",
       "149               True     False          False   \n",
       "150              False     False          False   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [team, position, data, analytics, team, smart,...   \n",
       "1    [great, involved, delivery, analytics, proof, ...   \n",
       "2    [modern, manufacturing, longer, finding, ways,...   \n",
       "3    [alignment, digitalisation, data, analytics, s...   \n",
       "4    [statement, dolutegravir, “, dtg, ”, first, ap...   \n",
       "..                                                 ...   \n",
       "146  [office, location, jurong, hiring, manager, am...   \n",
       "147  [·provide, detailed, documentation, capture, p...   \n",
       "148  [responsibilities, draw, flow, charts, visuali...   \n",
       "149  [impact, sales, operations, intern, apj, suppo...   \n",
       "150  [aspiring, digital, transformer, onboard, hr, ...   \n",
       "\n",
       "                                                  lems  \\\n",
       "0    [team, position, data, analytics, team, smart,...   \n",
       "1    [great, involved, delivery, analytics, proof, ...   \n",
       "2    [modern, manufacturing, longer, finding, way, ...   \n",
       "3    [alignment, digitalisation, data, analytics, s...   \n",
       "4    [statement, dolutegravir, “, dtg, ”, first, ap...   \n",
       "..                                                 ...   \n",
       "146  [office, location, jurong, hiring, manager, am...   \n",
       "147  [·provide, detailed, documentation, capture, p...   \n",
       "148  [responsibility, draw, flow, chart, visualize,...   \n",
       "149  [impact, sale, operation, intern, apj, support...   \n",
       "150  [aspiring, digital, transformer, onboard, hr, ...   \n",
       "\n",
       "                                                tagged  \\\n",
       "0    [(team, NN), (position, NN), (data, NNS), (ana...   \n",
       "1    [(great, JJ), (involved, JJ), (delivery, NN), ...   \n",
       "2    [(modern, JJ), (manufacturing, NN), (longer, R...   \n",
       "3    [(alignment, JJ), (digitalisation, NN), (data,...   \n",
       "4    [(statement, NN), (dolutegravir, NN), (“, NNP)...   \n",
       "..                                                 ...   \n",
       "146  [(office, NN), (location, NN), (jurong, IN), (...   \n",
       "147  [(·provide, RB), (detailed, JJ), (documentatio...   \n",
       "148  [(responsibility, NN), (draw, NN), (flow, JJ),...   \n",
       "149  [(impact, JJ), (sale, NN), (operation, NN), (i...   \n",
       "150  [(aspiring, VBG), (digital, JJ), (transformer,...   \n",
       "\n",
       "                                                 stems  \\\n",
       "0    [team, posit, data, analyt, team, smart, manuf...   \n",
       "1    [great, involv, deliveri, analyt, proof, conce...   \n",
       "2    [modern, manufactur, longer, find, way, oper, ...   \n",
       "3    [align, digitalis, data, analyt, strategi, exi...   \n",
       "4    [statement, dolutegravir, “, dtg, ”, first, ap...   \n",
       "..                                                 ...   \n",
       "146  [offic, locat, jurong, hire, manag, amt, singa...   \n",
       "147  [·provid, detail, document, captur, project, r...   \n",
       "148  [respons, draw, flow, chart, visual, workflow,...   \n",
       "149  [impact, sale, oper, intern, apj, support, ove...   \n",
       "150  [aspir, digit, transform, onboard, hr, digit, ...   \n",
       "\n",
       "                                          cleaned_text  \\\n",
       "0    team position data analytics team manufacturin...   \n",
       "1    delivery analytics proof concept play executio...   \n",
       "2    manufacturing finding way operate reducing exp...   \n",
       "3    digitalisation data analytics strategy exists ...   \n",
       "4    statement dolutegravir dtg approved state food...   \n",
       "..                                                 ...   \n",
       "146  office location hiring manager amt singapore p...   \n",
       "147  documentation capture project requirement stan...   \n",
       "148  responsibility draw chart visualize process ga...   \n",
       "149  sale operation apj supporting life science pro...   \n",
       "150  aspiring transformer onboard hr workplace team...   \n",
       "\n",
       "              normalized_title  \\\n",
       "0               data scientist   \n",
       "1               data scientist   \n",
       "2               data scientist   \n",
       "3    machine learning engineer   \n",
       "4    machine learning engineer   \n",
       "..                         ...   \n",
       "146             data scientist   \n",
       "147             data scientist   \n",
       "148           business analyst   \n",
       "149           business analyst   \n",
       "150  machine learning engineer   \n",
       "\n",
       "                                             key_words  \n",
       "0    {'smarc': 0.208, 'manufacturing': 0.186, 'anal...  \n",
       "1    {'science': 0.162, 'data science': 0.16, 'code...  \n",
       "2    {'site': 0.26, 'manufacturing': 0.2, 'way': 0....  \n",
       "3    {'phase': 0.297, 'dashboard': 0.21, 'student':...  \n",
       "4    {'twin': 0.368, 'plant': 0.24, 'campaign': 0.2...  \n",
       "..                                                 ...  \n",
       "146  {'gsk': 0.213, 'disease': 0.199, 'place': 0.16...  \n",
       "147  {'format': 0.15, 'data format': 0.15, 'configu...  \n",
       "148  {'visualize process': 0.158, 'user test': 0.15...  \n",
       "149  {'sale': 0.465, 'sale operation': 0.302, 'anal...  \n",
       "150  {'successfactor': 0.243, 'digitalization': 0.1...  \n",
       "\n",
       "[151 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter by job_title by finding all jobs containing the tokens of the preferred job_title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f46982a43929a109333ee597d4e43041bb82bdf689e9c7f608f0039a8f96ec65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
